import os
import cv2
import time
import numpy as np
import joblib
from skimage.feature import hog
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QGridLayout, QPushButton,
    QLabel, QTextEdit, QFileDialog, QMessageBox, QFrame
)
from PyQt5.QtGui import QPixmap, QFont
from PyQt5.QtCore import Qt

# ===============================
# Feature Extraction
# ===============================
def compute_angles(contour):
    peri = cv2.arcLength(contour, True)
    approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
    angles = []
    if len(approx) >= 3:
        for i in range(len(approx)):
            p1 = approx[i][0]
            p2 = approx[(i-1) % len(approx)][0]
            p3 = approx[(i+1) % len(approx)][0]
            v1 = p1 - p2
            v2 = p3 - p1
            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-7)
            angle = np.arccos(np.clip(cos_angle, -1, 1)) * 180 / np.pi
            angles.append(angle)
    while len(angles) < 6:
        angles.append(0)
    return np.array(angles[:6])

def extract_features(image, contour=None):
    image_resized = cv2.resize(image, (28, 28))
    feat_hog = hog(image_resized, orientations=9, pixels_per_cell=(8, 8),
                   cells_per_block=(2, 2), visualize=False)
    moments = cv2.moments(image_resized)
    hu_moments = cv2.HuMoments(moments).flatten()
    hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-7)
    
    if contour is not None:
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        circularity = 4 * np.pi * area / (perimeter**2 + 1e-7)
        epsilon = 0.02 * perimeter
        approx = cv2.approxPolyDP(contour, epsilon, True)
        num_vertices = len(approx)
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = w / h
        angles = compute_angles(contour)
        features = np.concatenate([feat_hog, hu_moments,
                                   [circularity, num_vertices, aspect_ratio],
                                   angles])
    else:
        features = np.concatenate([feat_hog, hu_moments, [0, 0, 0], np.zeros(6)])
    return features

# ===============================
# Dataset Loader
# ===============================
def load_shape_dataset(root_dir="shapes"):
    X, y = [], []
    for label in os.listdir(root_dir):
        class_folder = os.path.join(root_dir, label)
        if not os.path.isdir(class_folder):
            continue
        for file in os.listdir(class_folder):
            if file.lower().endswith((".png", ".jpg", ".jpeg", ".bmp")):
                img_path = os.path.join(class_folder, file)
                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                if img is None:
                    continue
                _, thresh = cv2.threshold(img, 127, 255,
                                          cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,
                                               cv2.CHAIN_APPROX_SIMPLE)
                contour = contours[0] if contours else None
                feat = extract_features(img, contour)
                X.append(feat)
                y.append(label)
    return np.array(X), np.array(y)

# ===============================
# Train Model
# ===============================
def train_and_save_model(X, y, model_path="shape_model.pkl"):
    start_time = time.time()
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )
    clf = SVC(kernel='rbf', C=10, gamma='scale', probability=True)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    train_time = time.time() - start_time
    joblib.dump(clf, model_path)
    return clf, acc, train_time

# ===============================
# Segment Shapes
# ===============================
def segment_shapes(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img.copy()
    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    shapes = []
    for c in contours:
        if cv2.contourArea(c) < 100:
            continue
        x, y, w, h = cv2.boundingRect(c)
        shape_img = gray[y:y+h, x:x+w]
        shapes.append((shape_img, (x, y, w, h), c))
    return shapes

# ===============================
# GUI Application (UI Improved)
# ===============================
class ShapeApp(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ðŸ”· Shape Recognition System")
        self.setGeometry(200, 200, 1000, 700)
        self.uploaded_image = None
        self.clf = None
        self.init_ui()

    def init_ui(self):
        # Main Grid Layout
        main_layout = QGridLayout()

        # Title
        title = QLabel("Simple Edge Detection & Shape Recognition")
        title.setFont(QFont("Arial", 16, QFont.Bold))
        title.setAlignment(Qt.AlignCenter)
        title.setStyleSheet("color: #2c3e50; margin: 10px;")
        main_layout.addWidget(title, 0, 0, 1, 2)

        # ===== Left Panel =====
        left_panel = QFrame()
        left_layout = QVBoxLayout()
        self.train_btn = QPushButton("ðŸ“˜ Train Shape Dataset")
        self.upload_btn = QPushButton("ðŸ“‚ Upload Image")
        self.predict_btn = QPushButton("ðŸ” Predict Shapes")

        # Button style
        for btn in [self.train_btn, self.upload_btn, self.predict_btn]:
            btn.setFont(QFont("Arial", 11))
            btn.setStyleSheet("""
                QPushButton {
                    background-color: #3498db; 
                    color: white; 
                    padding: 10px; 
                    border-radius: 8px;
                }
                QPushButton:hover { background-color: #2980b9; }
            """)
            left_layout.addWidget(btn)

        left_layout.addStretch()
        left_panel.setLayout(left_layout)
        left_panel.setStyleSheet("background: #ecf0f1; border-right: 2px solid #bdc3c7;")
        main_layout.addWidget(left_panel, 1, 0)

        # ===== Right Panel =====
        right_panel = QFrame()
        right_layout = QVBoxLayout()

        self.accuracy_label = QLabel("âš ï¸ Model not trained yet")
        self.accuracy_label.setFont(QFont("Arial", 11))
        self.accuracy_label.setStyleSheet("color: #e74c3c; margin: 5px;")
        right_layout.addWidget(self.accuracy_label)

        self.image_label = QLabel("No image uploaded")
        self.image_label.setAlignment(Qt.AlignCenter)
        self.image_label.setStyleSheet("border: 2px dashed #7f8c8d; background: #fafafa;")
        right_layout.addWidget(self.image_label, stretch=2)

        self.result_text = QTextEdit()
        self.result_text.setReadOnly(True)
        self.result_text.setFont(QFont("Courier", 10))
        self.result_text.setStyleSheet("""
            background: #fdfdfd; 
            border: 1px solid #bdc3c7; 
            padding: 5px;
        """)
        right_layout.addWidget(self.result_text, stretch=1)

        right_panel.setLayout(right_layout)
        main_layout.addWidget(right_panel, 1, 1)

        self.setLayout(main_layout)

        # Connect buttons
        self.train_btn.clicked.connect(self.train_model)
        self.upload_btn.clicked.connect(self.upload_image)
        self.predict_btn.clicked.connect(self.predict_image)

    def train_model(self):
        try:
            X, y = load_shape_dataset("shapes")
            if len(X) == 0:
                QMessageBox.warning(self, "Warning", "No dataset found!")
                return
            self.clf, acc, train_time = train_and_save_model(X, y)
            self.accuracy_label.setText(f"âœ… Accuracy: {acc:.2%} | â± Training Time: {train_time:.2f}s")
        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))

    def upload_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Open Image", "", "Images (*.png *.jpg *.jpeg *.bmp)"
        )
        if file_path:
            self.uploaded_image = file_path
            pixmap = QPixmap(file_path).scaled(600, 400, Qt.KeepAspectRatio)
            self.image_label.setPixmap(pixmap)

    def predict_image(self):
        if not self.uploaded_image:
            QMessageBox.warning(self, "Warning", "Please upload an image first.")
            return
        if self.clf is None:
            try:
                self.clf = joblib.load("shape_model.pkl")
            except:
                QMessageBox.warning(self, "Warning", "Train the model first!")
                return
        img = cv2.imread(self.uploaded_image)
        segments = segment_shapes(img)
        if not segments:
            self.result_text.setText("No shapes detected.")
            return

        output_img = img.copy()
        results = []
        for shape_img, (x, y, w, h), contour in segments:
            feat = extract_features(shape_img, contour)
            probs = self.clf.predict_proba([feat])[0]
            pred_idx = np.argmax(probs)
            pred_label = self.clf.classes_[pred_idx]
            confidence = probs[pred_idx] * 100
            results.append(f"{pred_label} ({confidence:.1f}%)")

            cv2.rectangle(output_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            # ðŸ”µ Blue label text
            cv2.putText(output_img, f"{pred_label} ({confidence:.1f}%)", (x, y-5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

        temp_path = "temp_detected.png"
        cv2.imwrite(temp_path, output_img)
        pixmap = QPixmap(temp_path).scaled(600, 400, Qt.KeepAspectRatio)
        self.image_label.setPixmap(pixmap)
        self.result_text.setText("Detected shapes:\n" + "\n".join(results))

# ===============================
# Run
# ===============================
if __name__ == "__main__":
    app = QApplication([])
    window = ShapeApp()
    window.show()
    app.exec_()
