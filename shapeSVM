import os
import cv2
import time
import numpy as np
import joblib
from skimage.feature import hog
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QHBoxLayout, QGridLayout, QPushButton,
    QLabel, QTextEdit, QFileDialog, QMessageBox, QFrame, QDialog
)
from PyQt5.QtGui import QPixmap, QFont
from PyQt5.QtCore import Qt
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas

# ===============================
# Feature Extraction
# ===============================
def compute_angles(contour):
    peri = cv2.arcLength(contour, True)
    approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
    angles = []
    if len(approx) >= 3:
        for i in range(len(approx)):
            p1 = approx[i][0]
            p2 = approx[(i-1) % len(approx)][0]
            p3 = approx[(i+1) % len(approx)][0]
            v1 = p1 - p2
            v2 = p3 - p1
            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-7)
            angle = np.arccos(np.clip(cos_angle, -1, 1)) * 180 / np.pi
            angles.append(angle)
    while len(angles) < 6:
        angles.append(0)
    return np.array(angles[:6])

def extract_features(image, contour=None):
    image_resized = cv2.resize(image, (28, 28))
    feat_hog = hog(image_resized, orientations=9, pixels_per_cell=(8, 8),
                   cells_per_block=(2, 2), visualize=False)
    moments = cv2.moments(image_resized)
    hu_moments = cv2.HuMoments(moments).flatten()
    hu_moments = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-7)

    if contour is not None:
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        circularity = 4 * np.pi * area / (perimeter**2 + 1e-7)
        epsilon = 0.02 * perimeter
        approx = cv2.approxPolyDP(contour, epsilon, True)
        num_vertices = len(approx)
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = w / h
        angles = compute_angles(contour)
        features = np.concatenate([feat_hog, hu_moments,
                                   [circularity, num_vertices, aspect_ratio],
                                   angles])
    else:
        features = np.concatenate([feat_hog, hu_moments, [0, 0, 0], np.zeros(6)])
    return features

# ===============================
# Dataset Loader
# ===============================
def load_shape_dataset(root_dir="shapes"):
    X, y = [], []
    for label in os.listdir(root_dir):
        class_folder = os.path.join(root_dir, label)
        if not os.path.isdir(class_folder):
            continue
        for file in os.listdir(class_folder):
            if file.lower().endswith((".png", ".jpg", ".jpeg", ".bmp")):
                img_path = os.path.join(class_folder, file)
                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                if img is None:
                    continue
                _, thresh = cv2.threshold(img, 127, 255,
                                          cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,
                                               cv2.CHAIN_APPROX_SIMPLE)
                contour = contours[0] if contours else None
                feat = extract_features(img, contour)
                X.append(feat)
                y.append(label)
    return np.array(X), np.array(y)

# ===============================
# Train Model
# ===============================
def train_and_save_model(X, y, model_path="shape_model.pkl"):
    start_time = time.time()
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )
    clf = SVC(kernel='rbf', C=10, gamma='scale', probability=True)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    train_time = time.time() - start_time
    joblib.dump(clf, model_path)
    return clf, train_time, X_train, X_test, y_train, y_test

# ===============================
# Segment Shapes
# ===============================
def segment_shapes(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img.copy()
    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    shapes = []
    for c in contours:
        if cv2.contourArea(c) < 100:
            continue
        x, y, w, h = cv2.boundingRect(c)
        shape_img = gray[y:y+h, x:x+w]
        shapes.append((shape_img, (x, y, w, h), c))
    return shapes

# ===============================
# GUI Application
# ===============================
class ShapeApp(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("🔷 Shape Recognition System")
        self.setGeometry(200, 200, 1000, 700)
        self.uploaded_image = None
        self.clf = None
        self.max_display_width = 600
        self.max_display_height = 600
        self.X_dataset = None
        self.y_dataset = None
        self.init_ui()

    def init_ui(self):
        main_layout = QGridLayout()

        # Title
        title = QLabel("Simple Edge Detection & Shape Recognition")
        title.setFont(QFont("Arial", 16, QFont.Bold))
        title.setAlignment(Qt.AlignCenter)
        title.setStyleSheet("color: #2c3e50; margin: 10px;")
        main_layout.addWidget(title, 0, 0, 1, 2)

        # ===== Left Panel =====
        left_panel = QFrame()
        left_layout = QVBoxLayout()
        self.train_btn = QPushButton("📘 Train Shape Dataset")
        self.upload_btn = QPushButton("📂 Upload Image")
        self.predict_btn = QPushButton("🔍 Predict Shapes")

        for btn in [self.train_btn, self.upload_btn, self.predict_btn]:
            btn.setFont(QFont("Arial", 11))
            btn.setStyleSheet("""
                QPushButton {
                    background-color: #3498db; 
                    color: white; 
                    padding: 10px; 
                    border-radius: 8px;
                }
                QPushButton:hover { background-color: #2980b9; }
            """)
            left_layout.addWidget(btn)

        left_layout.addStretch()
        left_panel.setLayout(left_layout)
        left_panel.setStyleSheet("background: #ecf0f1; border-right: 2px solid #bdc3c7;")
        main_layout.addWidget(left_panel, 1, 0)

        # ===== Right Panel (image left, result right) =====
        right_panel = QFrame()
        right_layout = QHBoxLayout()

        # Image Label
        self.image_label = QLabel("No image uploaded")
        self.image_label.setAlignment(Qt.AlignCenter)
        self.image_label.setStyleSheet("border: 2px dashed #7f8c8d; background: #fafafa;")
        right_layout.addWidget(self.image_label, stretch=3)

        # Result Text
        result_frame = QFrame()
        result_layout = QVBoxLayout()
        self.accuracy_label = QLabel("⚠️ Model not trained yet")
        self.accuracy_label.setFont(QFont("Arial", 11))
        self.accuracy_label.setStyleSheet("color: #e74c3c; margin: 5px;")
        result_layout.addWidget(self.accuracy_label)
        self.result_text = QTextEdit()
        self.result_text.setReadOnly(True)
        self.result_text.setFont(QFont("Courier", 10))
        self.result_text.setStyleSheet("""background: #fdfdfd; border: 1px solid #bdc3c7; padding: 5px;""")
        result_layout.addWidget(self.result_text)
        result_frame.setLayout(result_layout)
        right_layout.addWidget(result_frame, stretch=2)

        right_panel.setLayout(right_layout)
        main_layout.addWidget(right_panel, 1, 1)

        self.setLayout(main_layout)

        # Connect buttons
        self.train_btn.clicked.connect(self.train_model)
        self.upload_btn.clicked.connect(self.upload_image)
        self.predict_btn.clicked.connect(self.predict_image)

    # ======== Train ========
    def train_model(self):
        try:
            self.X_dataset, self.y_dataset = load_shape_dataset("shapes")
            if len(self.X_dataset) == 0:
                QMessageBox.warning(self, "Warning", "No dataset found!")
                return
            self.clf, train_time, X_train, X_test, y_train, y_test = train_and_save_model(self.X_dataset, self.y_dataset)
            train_acc = self.clf.score(X_train, y_train)
            test_acc = self.clf.score(X_test, y_test)
            self.accuracy_label.setText(f"✅ Train: {train_acc:.2%} | Test: {test_acc:.2%} | ⏱ {train_time:.2f}s")

            self.show_model_performance(self.clf, X_train, y_train, X_test, y_test)

        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))

    # ======== Upload ========
    def upload_image(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Open Image", "", "Images (*.png *.jpg *.jpeg *.bmp)")
        if file_path:
            self.uploaded_image = file_path
            pixmap = QPixmap(file_path)
            if pixmap.width() > self.max_display_width or pixmap.height() > self.max_display_height:
                pixmap = pixmap.scaled(self.max_display_width, self.max_display_height, Qt.KeepAspectRatio)
            self.image_label.setFixedSize(pixmap.width()+50, pixmap.height())
            self.image_label.setPixmap(pixmap)

    # ======== Predict ========
    def predict_image(self):
        if not self.uploaded_image:
            QMessageBox.warning(self, "Warning", "Please upload an image first.")
            return
        if self.clf is None:
            try:
                self.clf = joblib.load("shape_model.pkl")
            except:
                QMessageBox.warning(self, "Warning", "Train the model first!")
                return

        img = cv2.imread(self.uploaded_image)
        segments = segment_shapes(img)
        if not segments:
            self.result_text.setText("No shapes detected.")
            return

        output_img = img.copy()
        detected_shapes = []
        shape_count = {}
        detected_confidences = []

        label_offsets = {}

        for shape_img, (x, y, w, h), contour in segments:
            feat = extract_features(shape_img, contour)
            probs = self.clf.predict_proba([feat])[0]
            pred_idx = np.argmax(probs)
            pred_label = self.clf.classes_[pred_idx]
            confidence = probs[pred_idx] * 100
            detected_shapes.append((pred_label, confidence))
            detected_confidences.append((pred_label, confidence))
            shape_count[pred_label] = shape_count.get(pred_label, 0) + 1

            cv2.rectangle(output_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            offset = label_offsets.get(x, 0)
            text_y = max(y - 5 - offset, 15)
            label_offsets[x] = offset + 25
            text = f"{pred_label} ({confidence:.1f}%)"
            (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(output_img, (x, text_y - text_height - 3), (x + text_width, text_y + 3), (255, 255, 255), -1)
            cv2.putText(output_img, text, (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

        temp_path = "temp_detected.png"
        cv2.imwrite(temp_path, output_img)
        pixmap = QPixmap(temp_path)
        if pixmap.width() > self.max_display_width or pixmap.height() > self.max_display_height:
            pixmap = pixmap.scaled(self.max_display_width, self.max_display_height, Qt.KeepAspectRatio)
        self.image_label.setFixedSize(pixmap.width(), pixmap.height())
        self.image_label.setPixmap(pixmap)

        # Format result text
        result_msg = "==Detected Shapes with Confidence==\n"
        for label, conf in detected_shapes:
            result_msg += f"{label} ({conf:.1f}%)\n"
        result_msg += "\n===Total shape and the average confidence===\n"
        for label in shape_count:
            confidences = [c for l, c in detected_confidences if l == label]
            avg_conf = np.mean(confidences)
            result_msg += f"{label}: {shape_count[label]} (avg {avg_conf:.1f}%)\n"

        self.result_text.setText(result_msg)

    # ======== Model Performance Window ========
    def show_model_performance(self, clf, X_train, y_train, X_test, y_test):
        dialog = QDialog(self)
        dialog.setWindowTitle("Model Performance & Report")
        dialog.setGeometry(300, 200, 600, 600)
        layout = QVBoxLayout()
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        text_edit.setFont(QFont("Courier", 10))

        y_pred = clf.predict(X_test)
        report = classification_report(y_test, y_pred)
        train_acc = clf.score(X_train, y_train)
        test_acc = clf.score(X_test, y_test)

        # Regression-like metrics
        le = LabelEncoder()
        y_test_enc = le.fit_transform(y_test)
        y_pred_enc = le.transform(y_pred)
        mae = mean_absolute_error(y_test_enc, y_pred_enc)
        mse = mean_squared_error(y_test_enc, y_pred_enc)
        r2 = r2_score(y_test_enc, y_pred_enc)

        msg = f"✅ Train Accuracy: {train_acc:.2%}\n"
        msg += f"✅ Test Accuracy: {test_acc:.2%}\n\n"
        msg += "=== Classification Report ===\n" + report + "\n"
        msg += "=== Model Performance ===\n"
        msg += f"MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}"
        text_edit.setText(msg)
        layout.addWidget(text_edit)
        dialog.setLayout(layout)
        dialog.exec_()

        # Confusion matrix heatmap
        self.show_confusion_matrix_dialog(y_test, y_pred, clf.classes_)

    def show_confusion_matrix_dialog(self, y_true, y_pred, classes):
        dialog = QDialog(self)
        dialog.setWindowTitle("Confusion Matrix")
        dialog.setGeometry(350, 250, 500, 400)
        layout = QVBoxLayout()
        fig, ax = plt.subplots(figsize=(5,4))
        cm = confusion_matrix(y_true, y_pred, labels=classes)
        sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap="Blues", ax=ax)
        ax.set_xlabel("Predicted")
        ax.set_ylabel("Actual")
        canvas = FigureCanvas(fig)
        layout.addWidget(canvas)
        dialog.setLayout(layout)
        dialog.exec_()

# ===============================
# Run Application
# ===============================
if __name__ == "__main__":
    app = QApplication([])
    window = ShapeApp()
    window.show()
    app.exec_()
